# ğŸ¤ EpigrafIA - DetecciÃ³n Inteligente de Voz

<div align="center">

![EpigrafIA Logo](frontend/public/LOGOTyA_tfg.svg)

**Reconocimiento de idioma y acento usando Deep Learning, ejecutÃ¡ndose 100% en el navegador**

[![TensorFlow.js](https://img.shields.io/badge/TensorFlow.js-4.15.0-orange?logo=tensorflow)](https://www.tensorflow.org/js)
[![Astro](https://img.shields.io/badge/Astro-5.16.4-blueviolet?logo=astro)](https://astro.build)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind-4.1.17-38bdf8?logo=tailwindcss)](https://tailwindcss.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

[Demo en Vivo](#) | [DocumentaciÃ³n](#-caracterÃ­sticas) | [Contribuir](#-contribuciÃ³n)

</div>

---

## ğŸŒŸ CaracterÃ­sticas

### ğŸ¯ DetecciÃ³n de Idioma
Identifica automÃ¡ticamente entre **4 idiomas principales**:
- ğŸ‡ªğŸ‡¸ **EspaÃ±ol**
- ğŸ‡¬ğŸ‡§ **InglÃ©s**
- ğŸ‡«ğŸ‡· **FrancÃ©s**
- ğŸ‡©ğŸ‡ª **AlemÃ¡n**

### ğŸ—£ï¸ Profiling de Acento
Reconoce **8 acentos diferentes** con alta precisiÃ³n:
- ğŸ‡ªğŸ‡¸ EspaÃ±ol (EspaÃ±a) vs ğŸ‡²ğŸ‡½ (MÃ©xico)
- ğŸ‡¬ğŸ‡§ InglÃ©s (UK) vs ğŸ‡ºğŸ‡¸ (USA)
- ğŸ‡«ğŸ‡· FrancÃ©s (Francia) vs ğŸ‡¨ğŸ‡¦ (Quebec)
- ğŸ‡©ğŸ‡ª AlemÃ¡n (Alemania) vs ğŸ‡¦ğŸ‡¹ (Austria)

### âš¡ TecnologÃ­a de Vanguardia
- âœ… **100% Client-Side** - Sin backend, sin APIs externas
- âœ… **Deep Learning en el Navegador** - TensorFlow.js para inferencia en tiempo real
- âœ… **Redes Neuronales CNN** - Arquitectura optimizada para audio
- âœ… **MFCC Features** - AnÃ¡lisis espectral avanzado del audio
- âœ… **Interfaz Moderna** - DiseÃ±o responsive con Tailwind CSS 4
- âœ… **VisualizaciÃ³n en Tiempo Real** - Waveform animado del audio

---

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- **Node.js** >= 18.0.0
- **Python** >= 3.9 (solo para entrenamiento)
- **npm** o **yarn**

### InstalaciÃ³n Frontend

```bash
# Clonar repositorio
git clone https://github.com/adrianberlinchesayala25/EpigrafIA.git
cd EpigrafIA/frontend

# Instalar dependencias
npm install

# Ejecutar en desarrollo
npm run dev
```

Abre [http://localhost:4321](http://localhost:4321) en tu navegador ğŸ‰

### InstalaciÃ³n Backend (Entrenamiento)

```bash
# Volver al root del proyecto
cd ..

# Instalar dependencias Python
pip install -r requirements.txt

# Ejecutar notebooks de entrenamiento
jupyter notebook notebooks/train_language_model.ipynb
```

---

## ğŸ“ Estructura del Proyecto

```
EpigrafIA/
â”œâ”€â”€ ğŸ“‚ frontend/              # AplicaciÃ³n web (Astro + Tailwind)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ index.astro   # PÃ¡gina principal
â”‚   â”‚   â”œâ”€â”€ components/       # Componentes reutilizables
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ modelLoader.js        # Carga de modelos TF.js
â”‚   â”‚       â””â”€â”€ audioProcessing.js    # ExtracciÃ³n de MFCC
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ models/           # Modelos TensorFlow.js
â”‚   â”‚   â”‚   â”œâ”€â”€ language/     # Modelo de idiomas
â”‚   â”‚   â”‚   â””â”€â”€ accent/       # Modelo de acentos
â”‚   â”‚   â””â”€â”€ LOGOTyA_tfg.svg   # Logo animado
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/             # Entrenamiento de modelos
â”‚   â”œâ”€â”€ train_language_model.ipynb
â”‚   â””â”€â”€ train_accent_model.ipynb
â”‚
â”œâ”€â”€ ğŸ“‚ data/                  # Datasets (no incluido en repo)
â”‚   â””â”€â”€ Common Voice/
â”‚       â”œâ”€â”€ Audios EspaÃ±ol/   (2000 audios + validated.tsv)
â”‚       â”œâ”€â”€ Audios Ingles/    (2000 audios + validated.tsv)
â”‚       â”œâ”€â”€ Audios Frances/   (2000 audios + validated.tsv)
â”‚       â””â”€â”€ Audios Aleman/    (2000 audios + validated.tsv)
â”‚
â”œâ”€â”€ requirements.txt          # Dependencias Python
â””â”€â”€ README.md                 # Este archivo
```

---

## ğŸ§  Arquitectura de los Modelos

### Red Neuronal Convolucional (CNN)

Ambos modelos (idiomas y acentos) utilizan una arquitectura CNN optimizada:

```python
Input: (130, 120) 
  â†“
Conv1D (64 filters) â†’ ReLU â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.3)
  â†“
Conv1D (128 filters) â†’ ReLU â†’ BatchNorm â†’ MaxPool â†’ Dropout(0.3)
  â†“
Conv1D (256 filters) â†’ ReLU â†’ BatchNorm â†’ GlobalAvgPool
  â†“
Dense (128) â†’ ReLU â†’ Dropout(0.4)
  â†“
Dense (num_classes) â†’ Softmax
```

**Features de entrada:**
- **40 MFCC** + **40 Delta-MFCC** + **40 DeltaÂ²-MFCC**
- Ventanas de **3 segundos** a **16kHz**
- **130 time steps** por audio

**PrecisiÃ³n alcanzada:**
- ğŸ¯ **Idiomas:** ~92% accuracy
- ğŸ—£ï¸ **Acentos:** ~85% accuracy

---

## ğŸ¨ Flujo de Uso

1. **Grabar Audio** ğŸ™ï¸ o **Subir Archivo** ğŸ“
2. **VisualizaciÃ³n de Waveform** ğŸŒŠ
3. **AnÃ¡lisis Neural** ğŸ§ 
4. **Resultados InstantÃ¡neos** con probabilidades âš¡

---

## ğŸ› ï¸ Comandos Disponibles

### Frontend

| Comando | AcciÃ³n |
|---------|--------|
| `npm install` | Instalar dependencias |
| `npm run dev` | Servidor de desarrollo (puerto 4321) |
| `npm run build` | Build para producciÃ³n |
| `npm run preview` | Preview del build |

### Backend (Entrenamiento)

| Comando | AcciÃ³n |
|---------|--------|
| `pip install -r requirements.txt` | Instalar librerÃ­as Python |
| `jupyter notebook` | Abrir notebooks de entrenamiento |
| `python -m tensorflowjs_converter ...` | Convertir modelos a TF.js |

---

## ğŸ“Š Dataset

El proyecto utiliza el dataset **Common Voice de Mozilla**, con:

- âœ… **8,000 audios** totales (2,000 por idioma)
- âœ… **Validados manualmente** (`validated.tsv`)
- âœ… **Metadatos completos** (duraciÃ³n, votos, etc.)
- âœ… **Multi-speaker** para generalizaciÃ³n

### Descarga del Dataset

1. Ve a [Mozilla Common Voice](https://commonvoice.mozilla.org/datasets)
2. Descarga los idiomas: EspaÃ±ol, InglÃ©s, FrancÃ©s, AlemÃ¡n
3. Coloca los audios en `data/Common Voice/Audios {Idioma}/`

---

## ğŸ”¬ TecnologÃ­as Utilizadas

### Frontend
- **Astro 5** - Framework web moderno
- **Tailwind CSS 4** - Estilos utility-first
- **TensorFlow.js** - Inferencia de ML en el navegador
- **Web Audio API** - GrabaciÃ³n y procesamiento de audio
- **Canvas API** - VisualizaciÃ³n de waveforms

### Backend / Training
- **TensorFlow 2.15** - Entrenamiento de modelos
- **Librosa** - Procesamiento de audio
- **NumPy & Pandas** - ManipulaciÃ³n de datos
- **Scikit-learn** - MÃ©tricas y validaciÃ³n
- **Matplotlib & Seaborn** - VisualizaciÃ³n de resultados

---

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add: Amazing Feature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**. Ver [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¨â€ğŸ’» Autor

**AdriÃ¡n Berlinches Ayala**

- GitHub: [@adrianberlinchesayala25](https://github.com/adrianberlinchesayala25)
- Email: [berlinchesayalaadrian@gmail.com]

---

## ğŸ™ Agradecimientos

- **Mozilla Common Voice** por el dataset pÃºblico
- **TensorFlow.js** por hacer posible ML en el navegador
- **Astro Team** por el increÃ­ble framework
- Comunidad de **Deep Learning en Audio**

---

<div align="center">

**â­ Si te gusta este proyecto, dale una estrella en GitHub! â­**

Hecho con â¤ï¸ y ğŸµ por AdriÃ¡n Berlinches

</div>
