{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† EpigrafIA - Language Detection Model Training\n",
                "\n",
                "This notebook trains a CNN model to detect 4 languages: Spanish, English, French, and German.\n",
                "\n",
                "## Pipeline:\n",
                "1. Load audio data from Common Voice dataset (2000 samples per language)\n",
                "2. Extract MFCC features (40 coefficients + deltas + delta¬≤)\n",
                "3. Build & train CNN architecture\n",
                "4. Evaluate performance\n",
                "5. Convert to TensorFlow.js format"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ Cell 1: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q tensorflow==2.15.0\n",
                "!pip install -q librosa==0.10.1\n",
                "!pip install -q pandas==2.1.3\n",
                "!pip install -q scikit-learn==1.3.2\n",
                "!pip install -q tensorflowjs==4.15.0\n",
                "!pip install -q matplotlib==3.8.2\n",
                "!pip install -q seaborn==0.13.0\n",
                "!pip install -q tqdm\n",
                "\n",
                "print(\"‚úÖ Dependencies installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è Cell 2: Configuration & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import librosa\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Set random seeds\n",
                "RANDOM_SEED = 42\n",
                "np.random.seed(RANDOM_SEED)\n",
                "tf.random.set_seed(RANDOM_SEED)\n",
                "\n",
                "# Audio configuration\n",
                "SAMPLE_RATE = 16000\n",
                "DURATION = 3  # seconds\n",
                "N_MFCC = 40\n",
                "N_FFT = 2048\n",
                "HOP_LENGTH = 512\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = '../data/Common Voice'\n",
                "OUTPUT_DIR = '../frontend/public/models'\n",
                "\n",
                "# Model parameters\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 50\n",
                "LEARNING_RATE = 0.001\n",
                "\n",
                "# Language mapping\n",
                "LANGUAGE_FOLDERS = {\n",
                "    'es': 'Audios Espa√±ol',\n",
                "    'en': 'Audios Ingles',\n",
                "    'fr': 'Audios Frances',\n",
                "    'de': 'Audios Aleman'\n",
                "}\n",
                "\n",
                "print(\"‚úÖ Configuration loaded\")\n",
                "print(f\"Sample Rate: {SAMPLE_RATE} Hz\")\n",
                "print(f\"Duration: {DURATION} seconds\")\n",
                "print(f\"MFCCs: {N_MFCC}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìÇ Cell 3: Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_audio_files(max_samples_per_lang=2000):\n",
                "    \"\"\"\n",
                "    Load audio file paths from Common Voice dataset\n",
                "    \"\"\"\n",
                "    audio_paths = []\n",
                "    labels = []\n",
                "    \n",
                "    for lang_code, folder_name in LANGUAGE_FOLDERS.items():\n",
                "        # Path to audio clips\n",
                "        clips_path = os.path.join(DATA_DIR, folder_name, 'clips')\n",
                "        \n",
                "        if not os.path.exists(clips_path):\n",
                "            print(f\"‚ö†Ô∏è Warning: {clips_path} not found\")\n",
                "            continue\n",
                "        \n",
                "        # Get all MP3 files\n",
                "        audio_files = [f for f in os.listdir(clips_path) if f.endswith('.mp3')]\n",
                "        \n",
                "        # Limit to max_samples_per_lang\n",
                "        audio_files = audio_files[:max_samples_per_lang]\n",
                "        \n",
                "        # Add full paths\n",
                "        for audio_file in audio_files:\n",
                "            full_path = os.path.join(clips_path, audio_file)\n",
                "            audio_paths.append(full_path)\n",
                "            labels.append(lang_code)\n",
                "        \n",
                "        print(f\"‚úÖ {lang_code}: {len(audio_files)} audios loaded\")\n",
                "    \n",
                "    return audio_paths, labels\n",
                "\n",
                "# Load data\n",
                "print(\"üìÇ Loading dataset...\")\n",
                "audio_paths, labels = load_audio_files(max_samples_per_lang=2000)\n",
                "\n",
                "print(f\"\\nüìä Total audios: {len(audio_paths)}\")\n",
                "print(\"\\nDistribution by language:\")\n",
                "for lang in set(labels):\n",
                "    count = labels.count(lang)\n",
                "    print(f\"  {lang}: {count} ({count/len(labels)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéµ Cell 4: MFCC Feature Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_mfcc_features(audio_path, sr=SAMPLE_RATE, duration=DURATION, n_mfcc=N_MFCC):\n",
                "    \"\"\"\n",
                "    Extract MFCC + deltas + delta-deltas from audio file\n",
                "    \n",
                "    Returns:\n",
                "        numpy array of shape (time_steps, n_mfcc * 3)\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Load audio\n",
                "        y, sr_orig = librosa.load(audio_path, sr=sr, duration=duration)\n",
                "        \n",
                "        # Ensure fixed duration\n",
                "        target_length = sr * duration\n",
                "        if len(y) < target_length:\n",
                "            # Pad with zeros\n",
                "            y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
                "        else:\n",
                "            # Truncate\n",
                "            y = y[:target_length]\n",
                "        \n",
                "        # Extract MFCC\n",
                "        mfcc = librosa.feature.mfcc(\n",
                "            y=y,\n",
                "            sr=sr,\n",
                "            n_mfcc=n_mfcc,\n",
                "            n_fft=N_FFT,\n",
                "            hop_length=HOP_LENGTH\n",
                "        )\n",
                "        \n",
                "        # Extract deltas\n",
                "        mfcc_delta = librosa.feature.delta(mfcc)\n",
                "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
                "        \n",
                "        # Concatenate features\n",
                "        features = np.concatenate([mfcc, mfcc_delta, mfcc_delta2], axis=0)\n",
                "        \n",
                "        # Transpose to (time_steps, features)\n",
                "        features = features.T\n",
                "        \n",
                "        # Normalize\n",
                "        mean = np.mean(features, axis=0)\n",
                "        std = np.std(features, axis=0)\n",
                "        features = (features - mean) / (std + 1e-8)\n",
                "        \n",
                "        return features\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error processing {audio_path}: {e}\")\n",
                "        return None\n",
                "\n",
                "# Test with one audio\n",
                "print(\"üß™ Testing feature extraction...\")\n",
                "test_features = extract_mfcc_features(audio_paths[0])\n",
                "if test_features is not None:\n",
                "    print(f\"‚úÖ Feature shape: {test_features.shape}\")\n",
                "    print(f\"   (time_steps={test_features.shape[0]}, features={test_features.shape[1]})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèóÔ∏è Cell 5: Prepare Full Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_dataset(audio_paths, labels):\n",
                "    \"\"\"\n",
                "    Process all audios and create arrays of features and labels\n",
                "    \"\"\"\n",
                "    X = []\n",
                "    y = []\n",
                "    \n",
                "    print(\"üîÑ Extracting features from all audios...\")\n",
                "    for audio_path, label in tqdm(zip(audio_paths, labels), total=len(audio_paths)):\n",
                "        features = extract_mfcc_features(audio_path)\n",
                "        \n",
                "        if features is not None:\n",
                "            X.append(features)\n",
                "            y.append(label)\n",
                "    \n",
                "    X = np.array(X)\n",
                "    y = np.array(y)\n",
                "    \n",
                "    return X, y\n",
                "\n",
                "# Process dataset\n",
                "X, y = prepare_dataset(audio_paths, labels)\n",
                "\n",
                "print(f\"\\n‚úÖ Dataset prepared:\")\n",
                "print(f\"   X shape: {X.shape}\")\n",
                "print(f\"   y shape: {y.shape}\")\n",
                "\n",
                "# Encode labels\n",
                "label_encoder = LabelEncoder()\n",
                "y_encoded = label_encoder.fit_transform(y)\n",
                "\n",
                "print(f\"\\nüè∑Ô∏è Classes: {label_encoder.classes_}\")\n",
                "print(f\"   Encoded as: {np.unique(y_encoded)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÄ Cell 6: Train/Val/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/Val/Test split (70/15/15)\n",
                "X_train, X_temp, y_train, y_temp = train_test_split(\n",
                "    X, y_encoded,\n",
                "    test_size=0.3,\n",
                "    random_state=RANDOM_SEED,\n",
                "    stratify=y_encoded\n",
                ")\n",
                "\n",
                "X_val, X_test, y_val, y_test = train_test_split(\n",
                "    X_temp, y_temp,\n",
                "    test_size=0.5,\n",
                "    random_state=RANDOM_SEED,\n",
                "    stratify=y_temp\n",
                ")\n",
                "\n",
                "print(\"üìä Dataset split:\")\n",
                "print(f\"   Train: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
                "print(f\"   Val:   {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
                "print(f\"   Test:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
                "\n",
                "print(\"\\nüìà Distribution in Train set:\")\n",
                "unique, counts = np.unique(y_train, return_counts=True)\n",
                "for cls, count in zip(unique, counts):\n",
                "    print(f\"   {label_encoder.classes_[cls]}: {count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† Cell 7: Build CNN Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_cnn_model(input_shape, num_classes):\n",
                "    \"\"\"\n",
                "    CNN architecture for language detection\n",
                "    \"\"\"\n",
                "    model = keras.Sequential([\n",
                "        # Input layer\n",
                "        keras.layers.Input(shape=input_shape),\n",
                "        \n",
                "        # Block 1: Low-level features\n",
                "        keras.layers.Conv1D(64, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.MaxPooling1D(pool_size=2),\n",
                "        keras.layers.Dropout(0.3),\n",
                "        \n",
                "        # Block 2: Mid-level features\n",
                "        keras.layers.Conv1D(128, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.MaxPooling1D(pool_size=2),\n",
                "        keras.layers.Dropout(0.3),\n",
                "        \n",
                "        # Block 3: High-level features\n",
                "        keras.layers.Conv1D(256, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.GlobalAveragePooling1D(),\n",
                "        \n",
                "        # Classification\n",
                "        keras.layers.Dense(128, activation='relu'),\n",
                "        keras.layers.Dropout(0.4),\n",
                "        keras.layers.Dense(num_classes, activation='softmax')\n",
                "    ])\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Create model\n",
                "input_shape = (X_train.shape[1], X_train.shape[2])  # (time_steps, features)\n",
                "num_classes = len(label_encoder.classes_)\n",
                "\n",
                "model = build_cnn_model(input_shape, num_classes)\n",
                "\n",
                "print(\"üß† Model Architecture:\")\n",
                "model.summary()\n",
                "\n",
                "# Compile\n",
                "model.compile(\n",
                "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Model compiled\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèãÔ∏è Cell 8: Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "callbacks = [\n",
                "    keras.callbacks.EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=10,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    keras.callbacks.ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=5,\n",
                "        min_lr=1e-6,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"üèãÔ∏è Training model...\")\n",
                "print(f\"Epochs: {EPOCHS}\")\n",
                "print(f\"Batch size: {BATCH_SIZE}\")\n",
                "\n",
                "# Train\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_val, y_val),\n",
                "    epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Training completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Cell 9: Visualize Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# Accuracy\n",
                "axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
                "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
                "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Accuracy')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Loss\n",
                "axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
                "axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
                "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Loss')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"üìä Training visualization complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Cell 10: Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "# Evaluate\n",
                "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
                "\n",
                "print(f\"üìà Test Set Results:\")\n",
                "print(f\"   Loss: {test_loss:.4f}\")\n",
                "print(f\"   Accuracy: {test_accuracy*100:.2f}%\")\n",
                "\n",
                "# Predictions\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "\n",
                "# Classification report\n",
                "print(\"\\nüìã Classification Report:\")\n",
                "print(classification_report(\n",
                "    y_test,\n",
                "    y_pred_classes,\n",
                "    target_names=label_encoder.classes_,\n",
                "    digits=3\n",
                "))\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred_classes)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(\n",
                "    cm,\n",
                "    annot=True,\n",
                "    fmt='d',\n",
                "    cmap='Blues',\n",
                "    xticklabels=label_encoder.classes_,\n",
                "    yticklabels=label_encoder.classes_,\n",
                "    cbar_kws={'label': 'Count'}\n",
                ")\n",
                "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n‚úÖ Evaluation complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ Cell 11: Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model\n",
                "model.save('../models/language_model.h5')\n",
                "print(\"‚úÖ Model saved: ../models/language_model.h5\")\n",
                "\n",
                "# Save label encoder\n",
                "joblib.dump(label_encoder, '../models/language_label_encoder.pkl')\n",
                "print(\"‚úÖ Label encoder saved\")\n",
                "\n",
                "# Save config\n",
                "config = {\n",
                "    'sample_rate': SAMPLE_RATE,\n",
                "    'duration': DURATION,\n",
                "    'n_mfcc': N_MFCC,\n",
                "    'n_fft': N_FFT,\n",
                "    'hop_length': HOP_LENGTH,\n",
                "    'classes': label_encoder.classes_.tolist(),\n",
                "    'input_shape': list(input_shape),\n",
                "    'test_accuracy': float(test_accuracy)\n",
                "}\n",
                "\n",
                "with open('../models/language_config.json', 'w') as f:\n",
                "    json.dump(config, f, indent=2)\n",
                "\n",
                "print(\"‚úÖ Configuration saved\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üåê Cell 12: Convert to TensorFlow.js"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflowjs as tfjs\n",
                "\n",
                "# Create output directory\n",
                "os.makedirs(os.path.join(OUTPUT_DIR, 'language'), exist_ok=True)\n",
                "\n",
                "# Convert model\n",
                "print(\"üîÑ Converting model to TensorFlow.js...\")\n",
                "\n",
                "tfjs.converters.save_keras_model(\n",
                "    model,\n",
                "    os.path.join(OUTPUT_DIR, 'language')\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Model converted and saved in: {OUTPUT_DIR}/language/\")\n",
                "print(\"\\nüìÅ Generated files:\")\n",
                "for file in os.listdir(os.path.join(OUTPUT_DIR, 'language')):\n",
                "    file_path = os.path.join(OUTPUT_DIR, 'language', file)\n",
                "    size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
                "    print(f\"   - {file} ({size:.2f} MB)\")\n",
                "\n",
                "# Copy config\n",
                "import shutil\n",
                "shutil.copy('../models/language_config.json', os.path.join(OUTPUT_DIR, 'language', 'config.json'))\n",
                "\n",
                "print(\"\\nüéâ Conversion complete!\")\n",
                "print(\"\\nModel is ready to use in the web application.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìã Cell 13: Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"üéâ LANGUAGE DETECTION MODEL - SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(f\"\\nüìä Dataset:\")\n",
                "print(f\"   Total audios: {len(X)}\")\n",
                "print(f\"   Languages: {', '.join(label_encoder.classes_)}\")\n",
                "print(f\"   Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
                "\n",
                "print(f\"\\nüß† Model:\")\n",
                "print(f\"   Architecture: CNN (3 Conv1D blocks)\")\n",
                "print(f\"   Parameters: {model.count_params():,}\")\n",
                "print(f\"   Input shape: {input_shape}\")\n",
                "print(f\"   Output classes: {num_classes}\")\n",
                "\n",
                "print(f\"\\nüéØ Performance:\")\n",
                "print(f\"   Test Accuracy: {test_accuracy*100:.2f}%\")\n",
                "print(f\"   Test Loss: {test_loss:.4f}\")\n",
                "\n",
                "print(f\"\\nüíæ Output Files:\")\n",
                "print(f\"   ‚úÖ {OUTPUT_DIR}/language/model.json\")\n",
                "print(f\"   ‚úÖ {OUTPUT_DIR}/language/*.bin\")\n",
                "print(f\"   ‚úÖ {OUTPUT_DIR}/language/config.json\")\n",
                "\n",
                "print(f\"\\nüöÄ Next Steps:\")\n",
                "print(f\"   1. Run the accent detection notebook (if needed)\")\n",
                "print(f\"   2. cd ../frontend\")\n",
                "print(f\"   3. npm install\")\n",
                "print(f\"   4. npm run dev\")\n",
                "print(f\"   5. Open http://localhost:4321\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}