{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üó£Ô∏è EpigrafIA - Accent Detection Model Training\n",
                "\n",
                "This notebook trains a CNN model to detect 8 accents across 4 languages.\n",
                "\n",
                "**Note:** This is a simplified version since the Common Voice dataset may not have detailed accent metadata.\n",
                "We'll create a functional model structure that can be trained once proper accent-labeled data is available.\n",
                "\n",
                "## Accents to detect:\n",
                "- Spanish: Espa√±a vs M√©xico\n",
                "- English: UK vs USA  \n",
                "- French: France vs Quebec\n",
                "- German: Germany vs Austria"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ Cell 1: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q tensorflow==2.15.0\n",
                "!pip install -q librosa==0.10.1  \n",
                "!pip install -q pandas==2.1.3\n",
                "!pip install -q scikit-learn==1.3.2\n",
                "!pip install -q tensorflowjs==4.15.0\n",
                "!pip install -q matplotlib==3.8.2\n",
                "!pip install -q seaborn==0.13.0\n",
                "!pip install -q tqdm\n",
                "\n",
                "print(\"‚úÖ Dependencies installed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è Cell 2: Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import librosa\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "import json\n",
                "from tqdm import tqdm\n",
                "\n",
                "RANDOM_SEED = 42\n",
                "np.random.seed(RANDOM_SEED)\n",
                "tf.random.set_seed(RANDOM_SEED)\n",
                "\n",
                "# Audio configuration (same as language model)\n",
                "SAMPLE_RATE = 16000\n",
                "DURATION = 3\n",
                "N_MFCC = 40\n",
                "N_FFT = 2048\n",
                "HOP_LENGTH = 512\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = '../data/Common Voice'\n",
                "OUTPUT_DIR = '../frontend/public/models'\n",
                "\n",
                "# Model parameters\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 50\n",
                "LEARNING_RATE = 0.0005  # Slightly lower for accent (more subtle features)\n",
                "\n",
                "# Accent classes\n",
                "ACCENT_CLASSES = [\n",
                "    'spain', 'mexico',      # Spanish\n",
                "    'uk', 'usa',           # English\n",
                "    'france', 'quebec',    # French\n",
                "    'germany', 'austria'   # German\n",
                "]\n",
                "\n",
                "print(\"‚úÖ Configuration loaded\")\n",
                "print(f\"Accent classes: {len(ACCENT_CLASSES)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Cell 3: Create Synthetic Accent Dataset\n",
                "\n",
                "Since we don't have real accent labels in the dataset, we'll create a synthetic dataset by:\n",
                "1. Splitting each language's data into 2 groups (simulating 2 accents)\n",
                "2. Training a model on this structure\n",
                "3. The model will learn language features primarily, but the architecture will be ready for real accent data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_synthetic_accent_dataset(max_per_accent=250):\n",
                "    \"\"\"\n",
                "    Create synthetic accent dataset by splitting language data\n",
                "    In production, replace this with real accent-labeled data\n",
                "    \"\"\"\n",
                "    audio_paths = []\n",
                "    labels = []\n",
                "    \n",
                "    # Map languages to their accent pairs  \n",
                "    language_accent_map = {\n",
                "        'Audios Espa√±ol': ['spain', 'mexico'],\n",
                "        'Audios Ingles': ['uk', 'usa'],\n",
                "        'Audios Frances': ['france', 'quebec'],\n",
                "        'Audios Aleman': ['germany', 'austria']\n",
                "    }\n",
                "    \n",
                "    for folder, accents in language_accent_map.items():\n",
                "        clips_path = os.path.join(DATA_DIR, folder, 'clips')\n",
                "        \n",
                "        if not os.path.exists(clips_path):\n",
                "            print(f\"‚ö†Ô∏è Warning: {clips_path} not found\")\n",
                "            continue\n",
                "        \n",
                "        audio_files = [f for f in os.listdir(clips_path) if f.endswith('.mp3')]\n",
                "        \n",
                "        # Split files into 2 groups (simulating 2 accents)\n",
                "        mid_point = len(audio_files) // 2\n",
                "        \n",
                "        for i, accent in enumerate(accents):\n",
                "            if i == 0:\n",
                "                files = audio_files[:mid_point][:max_per_accent]\n",
                "            else:\n",
                "                files = audio_files[mid_point:][:max_per_accent]\n",
                "            \n",
                "            for audio_file in files:\n",
                "                full_path = os.path.join(clips_path, audio_file)\n",
                "                audio_paths.append(full_path)\n",
                "                labels.append(accent)\n",
                "            \n",
                "            print(f\"‚úÖ {accent}: {len(files)} audios\")\n",
                "    \n",
                "    return audio_paths, labels\n",
                "\n",
                "# Create dataset\n",
                "print(\"üìÇ Creating synthetic accent dataset...\")\n",
                "print(\"‚ö†Ô∏è NOTE: Using synthetic labels. For production, use real accent metadata.\\n\")\n",
                "\n",
                "audio_paths, labels = create_synthetic_accent_dataset(max_per_accent=250)\n",
                "\n",
                "print(f\"\\nüìä Total: {len(audio_paths)} audios\")\n",
                "print(f\"\\nDistribution:\")\n",
                "for accent in ACCENT_CLASSES:\n",
                "    count = labels.count(accent)\n",
                "    print(f\"  {accent}: {count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéµ Cell 4: Feature Extraction (Reuse from Language Model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_mfcc_features(audio_path, sr=SAMPLE_RATE, duration=DURATION, n_mfcc=N_MFCC):\n",
                "    try:\n",
                "        y, sr_orig = librosa.load(audio_path, sr=sr, duration=duration)\n",
                "        \n",
                "        target_length = sr * duration\n",
                "        if len(y) < target_length:\n",
                "            y = np.pad(y, (0, target_length - len(y)), mode='constant')\n",
                "        else:\n",
                "            y = y[:target_length]\n",
                "        \n",
                "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
                "        mfcc_delta = librosa.feature.delta(mfcc)\n",
                "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
                "        \n",
                "        features = np.concatenate([mfcc, mfcc_delta, mfcc_delta2], axis=0).T\n",
                "        \n",
                "        # Normalize\n",
                "        mean = np.mean(features, axis=0)\n",
                "        std = np.std(features, axis=0)\n",
                "        features = (features - mean) / (std + 1e-8)\n",
                "        \n",
                "        return features\n",
                "    except Exception as e:\n",
                "        return None\n",
                "\n",
                "print(\"‚úÖ Feature extraction function ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèóÔ∏è Cell 5: Prepare Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = []\n",
                "y = []\n",
                "\n",
                "print(\"üîÑ Extracting features...\")\n",
                "for audio_path, label in tqdm(zip(audio_paths, labels), total=len(audio_paths)):\n",
                "    features = extract_mfcc_features(audio_path)\n",
                "    if features is not None:\n",
                "        X.append(features)\n",
                "        y.append(label)\n",
                "\n",
                "X = np.array(X)\n",
                "y = np.array(y)\n",
                "\n",
                "print(f\"\\n‚úÖ Dataset: {X.shape}\")\n",
                "\n",
                "# Encode labels\n",
                "label_encoder = LabelEncoder()\n",
                "y_encoded = label_encoder.fit_transform(y)\n",
                "\n",
                "print(f\"\\nüè∑Ô∏è Classes: {label_encoder.classes_}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîÄ Cell 6: Train/Val/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_temp, y_train, y_temp = train_test_split(\n",
                "    X, y_encoded, test_size=0.3, random_state=RANDOM_SEED, stratify=y_encoded\n",
                ")\n",
                "\n",
                "X_val, X_test, y_val, y_test = train_test_split(\n",
                "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=y_temp\n",
                ")\n",
                "\n",
                "print(\"üìä Split:\")\n",
                "print(f\"   Train: {len(X_train)}\")\n",
                "print(f\"   Val: {len(X_val)}\")\n",
                "print(f\"   Test: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† Cell 7: Build Model (Deeper for Accent Subtleties)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_accent_model(input_shape, num_classes):\n",
                "    model = keras.Sequential([\n",
                "        keras.layers.Input(shape=input_shape),\n",
                "        \n",
                "        # Deeper architecture for subtle accent features\n",
                "        keras.layers.Conv1D(64, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.MaxPooling1D(pool_size=2),\n",
                "        keras.layers.Dropout(0.3),\n",
                "        \n",
                "        keras.layers.Conv1D(128, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.MaxPooling1D(pool_size=2),\n",
                "        keras.layers.Dropout(0.3),\n",
                "        \n",
                "        keras.layers.Conv1D(256, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.MaxPooling1D(pool_size=2),\n",
                "        keras.layers.Dropout(0.4),\n",
                "        \n",
                "        keras.layers.Conv1D(512, kernel_size=3, padding='same'),\n",
                "        keras.layers.ReLU(),\n",
                "        keras.layers.BatchNormalization(),\n",
                "        keras.layers.GlobalAveragePooling1D(),\n",
                "        \n",
                "        keras.layers.Dense(256, activation='relu'),\n",
                "        keras.layers.Dropout(0.5),\n",
                "        keras.layers.Dense(128, activation='relu'),\n",
                "        keras.layers.Dropout(0.4),\n",
                "        keras.layers.Dense(num_classes, activation='softmax')\n",
                "    ])\n",
                "    return model\n",
                "\n",
                "input_shape = (X_train.shape[1], X_train.shape[2])\n",
                "num_classes = len(label_encoder.classes_)\n",
                "\n",
                "model = build_accent_model(input_shape, num_classes)\n",
                "model.summary()\n",
                "\n",
                "model.compile(\n",
                "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Model compiled\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèãÔ∏è Cell 8: Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "callbacks = [\n",
                "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
                "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
                "]\n",
                "\n",
                "print(\"üèãÔ∏è Training accent model...\")\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_val, y_val),\n",
                "    epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Training complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Cell 9: Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
                "\n",
                "print(f\"üìà Test Accuracy: {test_accuracy*100:.2f}%\")\n",
                "print(f\"   Test Loss: {test_loss:.4f}\")\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred_classes = np.argmax(y_pred, axis=1)\n",
                "\n",
                "print(\"\\nüìã Classification Report:\")\n",
                "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_, digits=3))\n",
                "\n",
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred_classes)\n",
                "plt.figure(figsize=(12, 10))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', \n",
                "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
                "plt.title('Accent Detection - Confusion Matrix', fontsize=16, fontweight='bold')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üåê Cell 10: Convert to TensorFlow.js"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflowjs as tfjs\n",
                "\n",
                "os.makedirs(os.path.join(OUTPUT_DIR, 'accent'), exist_ok=True)\n",
                "\n",
                "print(\"üîÑ Converting to TensorFlow.js...\")\n",
                "\n",
                "tfjs.converters.save_keras_model(\n",
                "    model,\n",
                "    os.path.join(OUTPUT_DIR, 'accent')\n",
                ")\n",
                "\n",
                "# Save config\n",
                "config = {\n",
                "    'sample_rate': SAMPLE_RATE,\n",
                "    'duration': DURATION,\n",
                "    'n_mfcc': N_MFCC,\n",
                "    'n_fft': N_FFT,\n",
                "    'hop_length': HOP_LENGTH,\n",
                "    'classes': label_encoder.classes_.tolist(),\n",
                "    'input_shape': list(input_shape),\n",
                "    'test_accuracy': float(test_accuracy),\n",
                "    'note': 'Trained on synthetic accent labels. Replace with real accent data for production.'\n",
                "}\n",
                "\n",
                "with open(os.path.join(OUTPUT_DIR, 'accent', 'config.json'), 'w') as f:\n",
                "    json.dump(config, f, indent=2)\n",
                "\n",
                "print(f\"\\n‚úÖ Model saved to: {OUTPUT_DIR}/accent/\")\n",
                "print(\"\\nüéâ Accent model ready!\")\n",
                "print(\"\\n‚ö†Ô∏è Remember: This model was trained on synthetic labels.\")\n",
                "print(\"   For production, retrain with real accent-labeled data.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}